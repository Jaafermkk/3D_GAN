{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Our 3D_GAN/simple-pytorch-3dgan/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb9lUbfKmCHl",
        "outputId": "8224fc0b-25ca-4380-e4a3-4f14820a13fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Our 3D_GAN/simple-pytorch-3dgan/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install visdom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C7WfP2GlK0I",
        "outputId": "9e24d1da-761e-4624-f081-3d5523669136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom) (6.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom) (1.16.0)\n",
            "Collecting jsonpatch (from visdom)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom) (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from visdom) (3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom) (9.4.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2023.7.22)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=24e96533b5df5aebd7d960678b386d161dfd660b0e13810d12a6d38b46a491a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: jsonpointer, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 visdom-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1GjpyBuIbH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "utils.py\n",
        "\n",
        "Some utility functions\n",
        "\n",
        "'''\n",
        "\n",
        "import scipy.ndimage as nd\n",
        "import scipy.io as io\n",
        "import matplotlib\n",
        "import params\n",
        "\n",
        "if params.device.type != 'cpu':\n",
        "    matplotlib.use('Agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.measure as sk\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def getVoxelFromMat(path, cube_len=64):\n",
        "    if cube_len == 32:\n",
        "        voxels = io.loadmat(path)['instance'] # 30x30x30\n",
        "        voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
        "\n",
        "    else:\n",
        "\n",
        "        voxels = io.loadmat(path)['instance'] # 30x30x30\n",
        "        voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
        "        voxels = nd.zoom(voxels, (2, 2, 2), mode='constant', order=0)\n",
        "        # print ('here')\n",
        "    # print (voxels.shape)\n",
        "    return voxels\n",
        "\n",
        "\n",
        "def getVFByMarchingCubes(voxels, threshold=0.5):\n",
        "    v, f = sk.marching_cubes_classic(voxels, level=threshold)\n",
        "    return v, f\n",
        "\n",
        "\n",
        "def plotVoxelVisdom(voxels, visdom, title):\n",
        "    v, f = getVFByMarchingCubes(voxels)\n",
        "    visdom.mesh(X=v, Y=f, opts=dict(opacity=0.5, title=title))\n",
        "\n",
        "\n",
        "def SavePloat_Voxels(voxels, path, iteration):\n",
        "    voxels = voxels[:8].__ge__(0.5)\n",
        "    fig = plt.figure(figsize=(32, 16))\n",
        "    gs = gridspec.GridSpec(2, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(voxels):\n",
        "        x, y, z = sample.nonzero()\n",
        "        ax = plt.subplot(gs[i], projection='3d')\n",
        "        ax.scatter(x, y, z, zdir='z', c='red')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        # ax.set_aspect('equal')\n",
        "    # print (path + '/{}.png'.format(str(iteration).zfill(3)))\n",
        "    plt.savefig(path + '/{}.png'.format(str(iteration).zfill(3)), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "class ShapeNetDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, args, train_or_val=\"train\"):\n",
        "\n",
        "\n",
        "        self.root = root\n",
        "        self.listdir = os.listdir(self.root)\n",
        "\n",
        "\n",
        "        data_size = len(self.listdir)\n",
        "        self.listdir = self.listdir[0:int(data_size)]\n",
        "\n",
        "        print ('data_size =', len(self.listdir))\n",
        "        self.args = args\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with open(self.root + self.listdir[index], \"rb\") as f:\n",
        "            volume = np.asarray(getVoxelFromMat(f, params.cube_len), dtype=np.float32)\n",
        "            # print (volume.shape)\n",
        "        return torch.FloatTensor(volume)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.listdir)\n",
        "\n",
        "\n",
        "def generateZ(args, batch):\n",
        "\n",
        "    if params.z_dis == \"norm\":\n",
        "        Z = torch.Tensor(batch, params.z_dim).normal_(0, 0.33).to(params.device)\n",
        "    elif params.z_dis == \"uni\":\n",
        "        Z = torch.randn(batch, params.z_dim).to(params.device).to(params.device)\n",
        "    else:\n",
        "        print(\"z_dist is not normal or uniform\")\n",
        "\n",
        "    return Z\n"
      ],
      "metadata": {
        "id": "4QdCMQfql0wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "trainer.py\n",
        "\n",
        "Train 3dgan models\n",
        "'''\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from utils import *\n",
        "import os\n",
        "\n",
        "from model import net_G, net_D\n",
        "\n",
        "# added\n",
        "import datetime\n",
        "import time\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import params\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def save_train_log(writer, loss_D, loss_G, itr):\n",
        "    scalar_info = {}\n",
        "    for key, value in loss_G.items():\n",
        "        scalar_info['train_loss_G/' + key] = value\n",
        "\n",
        "    for key, value in loss_D.items():\n",
        "        scalar_info['train_loss_D/' + key] = value\n",
        "\n",
        "    for tag, value in scalar_info.items():\n",
        "        writer.add_scalar(tag, value, itr)\n",
        "\n",
        "\n",
        "def save_val_log(writer, loss_D, loss_G, itr):\n",
        "    scalar_info = {}\n",
        "    for key, value in loss_G.items():\n",
        "        scalar_info['val_loss_G/' + key] = value\n",
        "\n",
        "    for key, value in loss_D.items():\n",
        "        scalar_info['val_loss_D/' + key] = value\n",
        "\n",
        "    for tag, value in scalar_info.items():\n",
        "        writer.add_scalar(tag, value, itr)\n",
        "\n",
        "\n",
        "def trainer(args):\n",
        "    # added for output dir\n",
        "    save_file_path = params.output_dir + '/' + args.model_name\n",
        "    print(save_file_path)\n",
        "    if not os.path.exists(save_file_path):\n",
        "        os.makedirs(save_file_path)\n",
        "\n",
        "    # for using tensorboard\n",
        "    if args.logs:\n",
        "        model_uid = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
        "        writer = SummaryWriter(params.output_dir + '/' + args.model_name + '/' + args.logs + '/logs')\n",
        "\n",
        "        image_saved_path = params.output_dir + '/' + args.model_name + '/' + args.logs + '/images'\n",
        "        model_saved_path = params.output_dir + '/' + args.model_name + '/' + args.logs + '/models'\n",
        "\n",
        "        if not os.path.exists(image_saved_path):\n",
        "            os.makedirs(image_saved_path)\n",
        "        if not os.path.exists(model_saved_path):\n",
        "            os.makedirs(model_saved_path)\n",
        "\n",
        "    dsets_path = params.data_dir + params.model_dir + \"30/train/\"\n",
        "\n",
        "\n",
        "    print(dsets_path)\n",
        "\n",
        "    train_dsets = ShapeNetDataset(dsets_path, args, \"train\")\n",
        "\n",
        "\n",
        "    train_dset_loaders = torch.utils.data.DataLoader(train_dsets, batch_size=params.batch_size, shuffle=True,\n",
        "                                                     num_workers=1)\n",
        "\n",
        "    dset_len = {\"train\": len(train_dsets)}\n",
        "    dset_loaders = {\"train\": train_dset_loaders}\n",
        "    # print (dset_len[\"train\"])\n",
        "\n",
        "    # model define\n",
        "    D = net_D(args)\n",
        "    G = net_G(args)\n",
        "\n",
        "    # print total number of parameters in a model\n",
        "    # x = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
        "    # print (x)\n",
        "    # x = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
        "    # print (x)\n",
        "\n",
        "    D_solver = optim.Adam(D.parameters(), lr=params.d_lr, betas=params.beta)\n",
        "    # D_solver = optim.SGD(D.parameters(), lr=args.d_lr, momentum=0.9)\n",
        "    G_solver = optim.Adam(G.parameters(), lr=params.g_lr, betas=params.beta)\n",
        "\n",
        "    D.to(params.device)\n",
        "    G.to(params.device)\n",
        "\n",
        "    criterion_D = nn.MSELoss()\n",
        "\n",
        "    criterion_G = nn.L1Loss()\n",
        "\n",
        "    itr_val = -1\n",
        "    itr_train = -1\n",
        "\n",
        "    for epoch in range(params.epochs):\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "\n",
        "                D.train()\n",
        "                G.train()\n",
        "            else:\n",
        "                D.eval()\n",
        "                G.eval()\n",
        "\n",
        "            running_loss_G = 0.0\n",
        "            running_loss_D = 0.0\n",
        "            running_loss_adv_G = 0.0\n",
        "\n",
        "            for i, X in enumerate(tqdm(dset_loaders[phase])):\n",
        "\n",
        "                # if phase == 'val':\n",
        "                #     itr_val += 1\n",
        "\n",
        "                if phase == 'train':\n",
        "                    itr_train += 1\n",
        "\n",
        "                X = X.to(params.device)\n",
        "                # print (X)\n",
        "                # print (X.size())\n",
        "\n",
        "                batch = X.size()[0]\n",
        "                # print (batch)\n",
        "\n",
        "                Z = generateZ(args, batch)\n",
        "                # print (Z.size())\n",
        "\n",
        "                # ============= Train the discriminator =============#\n",
        "                d_real = D(X)\n",
        "\n",
        "                fake = G(Z)\n",
        "                d_fake = D(fake)\n",
        "\n",
        "                real_labels = torch.ones_like(d_real).to(params.device)\n",
        "                fake_labels = torch.zeros_like(d_fake).to(params.device)\n",
        "                # print (d_fake.size(), fake_labels.size())\n",
        "\n",
        "                if params.soft_label:\n",
        "                    real_labels = torch.Tensor(batch).uniform_(0.7, 1.2).to(params.device)\n",
        "                    fake_labels = torch.Tensor(batch).uniform_(0, 0.3).to(params.device)\n",
        "\n",
        "                # print (d_real.size(), real_labels.size())\n",
        "                d_real_loss = criterion_D(d_real, real_labels)\n",
        "\n",
        "                d_fake_loss = criterion_D(d_fake, fake_labels)\n",
        "\n",
        "                d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "                d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
        "                d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
        "                d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu), 0))\n",
        "\n",
        "                if d_total_acu < params.d_thresh:\n",
        "                    D.zero_grad()\n",
        "                    d_loss.backward()\n",
        "                    D_solver.step()\n",
        "\n",
        "                # =============== Train the generator ===============#\n",
        "\n",
        "                Z = generateZ(args, batch)\n",
        "\n",
        "                # print (X)\n",
        "                fake = G(Z)\n",
        "                d_fake = D(fake)\n",
        "\n",
        "                adv_g_loss = criterion_D(d_fake, real_labels)\n",
        "\n",
        "                recon_g_loss = criterion_G(fake, X)\n",
        "\n",
        "                g_loss = adv_g_loss\n",
        "\n",
        "                if args.local_test:\n",
        "\n",
        "                    print('Iteration-{} , D(x) : {:.4}, D(G(x)) : {:.4}'.format(itr_train, d_loss.item(),\n",
        "                                                                                adv_g_loss.item()))\n",
        "\n",
        "                D.zero_grad()\n",
        "                G.zero_grad()\n",
        "                g_loss.backward()\n",
        "                G_solver.step()\n",
        "\n",
        "                # =============== logging each 10 iterations ===============#\n",
        "\n",
        "                running_loss_G += recon_g_loss.item() * X.size(0)\n",
        "                running_loss_D += d_loss.item() * X.size(0)\n",
        "                running_loss_adv_G += adv_g_loss.item() * X.size(0)\n",
        "\n",
        "                if args.logs:\n",
        "                    loss_G = {\n",
        "                        'adv_loss_G': adv_g_loss,\n",
        "                        'recon_loss_G': recon_g_loss,\n",
        "                    }\n",
        "\n",
        "                    loss_D = {\n",
        "                        'adv_real_loss_D': d_real_loss,\n",
        "                        'adv_fake_loss_D': d_fake_loss,\n",
        "                    }\n",
        "\n",
        "                    # if itr_val % 10 == 0 and phase == 'val':\n",
        "                    #     save_val_log(writer, loss_D, loss_G, itr_val)\n",
        "\n",
        "                    if itr_train % 10 == 0 and phase == 'train':\n",
        "                        save_train_log(writer, loss_D, loss_G, itr_train)\n",
        "\n",
        "            # =============== each epoch save model or save image ===============#\n",
        "            epoch_loss_G = running_loss_G / dset_len[phase]\n",
        "            epoch_loss_D = running_loss_D / dset_len[phase]\n",
        "            epoch_loss_adv_G = running_loss_adv_G / dset_len[phase]\n",
        "\n",
        "            end = time.time()\n",
        "            epoch_time = end - start\n",
        "\n",
        "            print('Epochs-{} ({}) , D(x) : {:.4}, D(G(x)) : {:.4}'.format(epoch, phase, epoch_loss_D, epoch_loss_adv_G))\n",
        "            print('Elapsed Time: {:.4} min'.format(epoch_time / 60.0))\n",
        "\n",
        "            if (epoch + 1) % params.model_save_step == 0:\n",
        "                print('model_saved, images_saved...')\n",
        "                torch.save(G.state_dict(), model_saved_path + '/G.pth')\n",
        "                torch.save(D.state_dict(), model_saved_path + '/D.pth')\n",
        "\n",
        "                samples = fake.cpu().data[:8].squeeze().numpy()\n",
        "\n",
        "\n",
        "                SavePloat_Voxels(samples, image_saved_path, epoch)\n"
      ],
      "metadata": {
        "id": "RtugsunBl6tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tester.py\n",
        "\n",
        "Test the trained 3dgan models\n",
        "'''\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "from utils import *\n",
        "import os\n",
        "from model import net_G, net_D\n",
        "\n",
        "import datetime\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import params\n",
        "import visdom\n",
        "\n",
        "\n",
        "def tester(args):\n",
        "    print('Evaluation Mode...')\n",
        "\n",
        "\n",
        "    image_saved_path = params.output_dir + '/' + args.model_name + '/' + args.logs + '/test_outputs'\n",
        "    if not os.path.exists(image_saved_path):\n",
        "        os.makedirs(image_saved_path)\n",
        "\n",
        "    if args.use_visdom:\n",
        "        vis = visdom.Visdom()\n",
        "\n",
        "    save_file_path = params.output_dir + '/' + args.model_name\n",
        "    pretrained_file_path_G = save_file_path + '/' + args.logs + '/models/G.pth'\n",
        "    pretrained_file_path_D = save_file_path + '/' + args.logs + '/models/D.pth'\n",
        "\n",
        "    print(pretrained_file_path_G)\n",
        "\n",
        "    D = net_D(args)\n",
        "    G = net_G(args)\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        G.load_state_dict(torch.load(pretrained_file_path_G, map_location={'cuda:0': 'cpu'}))\n",
        "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
        "    else:\n",
        "        G.load_state_dict(torch.load(pretrained_file_path_G))\n",
        "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
        "\n",
        "    print('visualizing model')\n",
        "\n",
        "\n",
        "    G.to(params.device)\n",
        "    D.to(params.device)\n",
        "    G.eval()\n",
        "    D.eval()\n",
        "\n",
        "\n",
        "    N = 8\n",
        "\n",
        "    for i in range(N):\n",
        "\n",
        "        z = generateZ(args, 1)\n",
        "\n",
        "\n",
        "        fake = G(z)\n",
        "        samples = fake.unsqueeze(dim=0).detach().cpu().numpy()\n",
        "        # print (samples.shape)\n",
        "        # print (fake)\n",
        "        y_prob = D(fake)\n",
        "        y_real = torch.ones_like(y_prob)\n",
        "\n",
        "        if not args.use_visdom:\n",
        "            SavePloat_Voxels(samples, image_saved_path, 'tester_' + str(i))  # norm_\n",
        "        else:\n",
        "            plotVoxelVisdom(samples[0, :], vis, \"tester_\" + str(i))\n"
      ],
      "metadata": {
        "id": "gmVWMAyKmLW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "params.py\n",
        "\n",
        "Managers of all hyper-parameters\n",
        "\n",
        "'''\n",
        "\n",
        "import torch\n",
        "\n",
        "epochs = 500\n",
        "batch_size = 32\n",
        "soft_label = False\n",
        "adv_weight = 0\n",
        "d_thresh = 0.8\n",
        "z_dim = 200\n",
        "z_dis = \"norm\"\n",
        "model_save_step = 1\n",
        "g_lr = 0.0025\n",
        "d_lr = 0.00001\n",
        "beta = (0.5, 0.999)\n",
        "cube_len = 32\n",
        "leak_value = 0.2\n",
        "bias = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data_dir = '../volumetric_data/'\n",
        "model_dir = 'chair/'\n",
        "output_dir = '../outputs'\n",
        "\n",
        "\n",
        "\n",
        "def print_params():\n",
        "    l = 16\n",
        "    print(l * '*' + 'hyper-parameters' + l * '*')\n",
        "\n",
        "    print('epochs =', epochs)\n",
        "    print('batch_size =', batch_size)\n",
        "    print('soft_labels =', soft_label)\n",
        "    print('adv_weight =', adv_weight)\n",
        "    print('d_thresh =', d_thresh)\n",
        "    print('z_dim =', z_dim)\n",
        "    print('z_dis =', z_dis)\n",
        "    print('model_images_save_step =', model_save_step)\n",
        "    print('data =', model_dir)\n",
        "    print('device =', device)\n",
        "    print('g_lr =', g_lr)\n",
        "    print('d_lr =', d_lr)\n",
        "    print('cube_len =', cube_len)\n",
        "    print('leak_value =', leak_value)\n",
        "    print('bias =', bias)\n",
        "\n",
        "    print(l * '*' + 'hyper-parameters' + l * '*')\n"
      ],
      "metadata": {
        "id": "f7DT_g9ambas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import params\n",
        "\n",
        "'''\n",
        "\n",
        "model.py\n",
        "\n",
        "Define our GAN model\n",
        "\n",
        "The cube_len is 32x32x32, and the maximum number of feature map is 256,\n",
        "so the results may be inconsistent with the paper\n",
        "\n",
        "'''\n",
        "\n",
        "class net_G(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(net_G, self).__init__()\n",
        "        self.args = args\n",
        "        self.cube_len = params.cube_len\n",
        "        self.bias = params.bias\n",
        "        self.z_dim = params.z_dim\n",
        "        self.f_dim = 32\n",
        "\n",
        "        padd = (0, 0, 0)\n",
        "        if self.cube_len == 32:\n",
        "            padd = (1,1,1)\n",
        "\n",
        "        self.layer1 = self.conv_layer(self.z_dim, self.f_dim*8, kernel_size=4, stride=2, padding=padd, bias=self.bias)\n",
        "        self.layer2 = self.conv_layer(self.f_dim*8, self.f_dim*4, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
        "        self.layer3 = self.conv_layer(self.f_dim*4, self.f_dim*2, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
        "        self.layer4 = self.conv_layer(self.f_dim*2, self.f_dim, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
        "\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(self.f_dim, 1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
        "            torch.nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "\n",
        "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
        "        layer = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
        "            torch.nn.BatchNorm3d(output_dim),\n",
        "            torch.nn.ReLU(True)\n",
        "\n",
        "        )\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(-1, self.z_dim, 1, 1, 1)\n",
        "        # print(out.size())  # torch.Size([32, 200, 1, 1, 1])\n",
        "        out = self.layer1(out)\n",
        "        # print(out.size())  # torch.Size([32, 256, 2, 2, 2])\n",
        "        out = self.layer2(out)\n",
        "\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.layer5(out)\n",
        "\n",
        "        out = torch.squeeze(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class net_D(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(net_D, self).__init__()\n",
        "        self.args = args\n",
        "        self.cube_len = params.cube_len\n",
        "        self.leak_value = params.leak_value\n",
        "        self.bias = params.bias\n",
        "\n",
        "        padd = (0,0,0)\n",
        "        if self.cube_len == 32:\n",
        "            padd = (1,1,1)\n",
        "\n",
        "        self.f_dim = 32\n",
        "\n",
        "        self.layer1 = self.conv_layer(1, self.f_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
        "        self.layer2 = self.conv_layer(self.f_dim, self.f_dim*2, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
        "        self.layer3 = self.conv_layer(self.f_dim*2, self.f_dim*4, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
        "        self.layer4 = self.conv_layer(self.f_dim*4, self.f_dim*8, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
        "\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(self.f_dim*8, 1, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
        "        layer = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
        "            torch.nn.BatchNorm3d(output_dim),\n",
        "            torch.nn.LeakyReLU(self.leak_value, inplace=True)\n",
        "        )\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = x.view(-1, 1, self.cube_len, self.cube_len, self.cube_len)\n",
        "        # print(out.size()) # torch.Size([32, 1, 32, 32, 32])\n",
        "        out = self.layer1(out)\n",
        "        # print(out.size())  # torch.Size([32, 32, 16, 16, 16])\n",
        "        out = self.layer2(out)\n",
        "        # print(out.size())  # torch.Size([32, 64, 8, 8, 8])\n",
        "        out = self.layer3(out)\n",
        "        # print(out.size())  # torch.Size([32, 128, 4, 4, 4])\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.layer5(out)\n",
        "        # print(out.size())  # torch.Size([32, 1, 1, 1, 1])\n",
        "        out = torch.squeeze(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "pf8GL6hVmw4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "main.py\n",
        "\n",
        "Welcome, this is the entrance to 3dgan\n",
        "'''\n",
        "\n",
        "import argparse\n",
        "from trainer import trainer\n",
        "import torch\n",
        "\n",
        "from tester import tester\n",
        "import params\n",
        "\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "\n",
        "def main():\n",
        "    # add arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # loggings parameters\n",
        "    parser.add_argument(\"-f\",'--logs', type=str, default='first_test', help='logs by tensorboardX')\n",
        "    parser.add_argument('--local_test', type=str2bool, default=False, help='local test verbose')\n",
        "    parser.add_argument('--model_name', type=str, default=\"dcgan\", help='model name for saving')\n",
        "    parser.add_argument('--test', type=str2bool, default=False, help='call tester.py')\n",
        "    parser.add_argument('--use_visdom', type=str2bool, default=False, help='visualization by visdom')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # list params\n",
        "    params.print_params()\n",
        "\n",
        "    # run program\n",
        "    if not args.test:\n",
        "        trainer(args)\n",
        "    else:\n",
        "        tester(args)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "zNJbp1SxnFNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}